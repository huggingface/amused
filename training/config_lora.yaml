experiment:
    project: "muse"
    max_train_examples: 3000000 # unused
    max_eval_examples: 20000 # unused
    save_every: 100
    generate_every: 100
    log_every: 50
    checkpoints_total_limit: 20


dataset:
    type: "text2image"
    params:
        instance_data_root: "/fsx/william/cat_toy"
        instance_prompt: "A photo of sks toy"
        batch_size: ${training.batch_size}
        num_workers: 1
        resolution: 512
        pin_memory: False
        persistent_workers: False
    preprocessing:
        max_seq_length: 77
        resolution: 512
        center_crop: False
        random_flip: False


training:
    max_train_steps: 2000
    cond_dropout_prob: 0.0
    min_masking_rate: 0.0
    label_smoothing: 0.0
    max_grad_norm: null
    guidance_scale: 8
    generation_timesteps: 16
    generation_temperature: 4.0
    use_stochastic_code: False
    soft_code_temp: 1.0
    mask_contiguous_region_prob: 0.0
    lora_r: 16
    lora_alpha: 32
    lora_target_modules: ["query", "key", "value"]